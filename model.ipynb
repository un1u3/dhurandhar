{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35bbd0d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# SECTION 1: SETUP & INSTALLATIONS\n",
    "# ==========================================\n",
    "# Run this first - installs all required packages\n",
    "\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install kaggle opendatasets pillow matplotlib seaborn scikit-learn\n",
    "!pip install pytorch-grad-cam\n",
    "!pip install timm  # For better model architectures\n",
    "\n",
    "print(\"âœ… All packages installed!\")\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 2: IMPORTS\n",
    "# ==========================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 3: DATASET DOWNLOAD (IMPROVED TB DATA)\n",
    "# ==========================================\n",
    "# This downloads ~6GB of data, takes 15-20 minutes\n",
    "\n",
    "import opendatasets as od\n",
    "\n",
    "# Dataset 1: Kaggle Chest X-Ray (Pneumonia)\n",
    "print(\"ðŸ“¥ Downloading Pneumonia Dataset...\")\n",
    "od.download(\"https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\")\n",
    "\n",
    "# Dataset 2: COVID-19 Radiography Database\n",
    "print(\"ðŸ“¥ Downloading COVID-19 Dataset...\")\n",
    "od.download(\"https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database\")\n",
    "\n",
    "# Dataset 3: TB Chest X-ray Database - Shenzhen (Higher Quality)\n",
    "print(\"ðŸ“¥ Downloading TB Dataset (Shenzhen)...\")\n",
    "od.download(\"https://www.kaggle.com/datasets/raddar/tuberculosis-chest-xrays-shenzhen\")\n",
    "\n",
    "# Dataset 4: TB Chest X-ray Database - Montgomery County (Additional TB data)\n",
    "print(\"ðŸ“¥ Downloading TB Dataset (Montgomery)...\")\n",
    "od.download(\"https://www.kaggle.com/datasets/raddar/tuberculosis-chest-xrays-montgomery\")\n",
    "\n",
    "# Dataset 5: TBX11K - Comprehensive TB Dataset (RECOMMENDED - Best Quality)\n",
    "print(\"ðŸ“¥ Downloading TBX11K Dataset (Large, High Quality)...\")\n",
    "try:\n",
    "    od.download(\"https://www.kaggle.com/datasets/usmanshams/tbx-11\")\n",
    "    print(\"âœ… TBX11K downloaded successfully!\")\n",
    "except:\n",
    "    print(\"âš ï¸ TBX11K not available, using other TB sources\")\n",
    "\n",
    "print(\"âœ… All datasets downloaded!\")\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 4: DATA ORGANIZATION (IMPROVED TB HANDLING)\n",
    "# ==========================================\n",
    "# Organize all datasets into a unified structure\n",
    "\n",
    "# Create organized directory structure\n",
    "base_dir = '/content/xray_dataset'\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for category in ['NORMAL', 'PNEUMONIA', 'COVID', 'TB']:\n",
    "        os.makedirs(f'{base_dir}/{split}/{category}', exist_ok=True)\n",
    "\n",
    "print(\"ðŸ“ Directory structure created!\")\n",
    "\n",
    "# Enhanced function to copy and organize images with quality checks\n",
    "def organize_images(source_paths, dest_base, label, split_ratio={'train': 0.7, 'val': 0.15, 'test': 0.15},\n",
    "                   min_image_size=(100, 100)):\n",
    "    \"\"\"\n",
    "    Organize images into train/val/test splits with quality filtering\n",
    "\n",
    "    Args:\n",
    "        source_paths: List of source directories\n",
    "        dest_base: Destination base directory\n",
    "        label: Class label\n",
    "        split_ratio: Train/val/test split ratios\n",
    "        min_image_size: Minimum image dimensions for quality control\n",
    "    \"\"\"\n",
    "    all_images = []\n",
    "    skipped = 0\n",
    "\n",
    "    for source_path in source_paths:\n",
    "        if os.path.exists(source_path):\n",
    "            print(f\"  ðŸ“‚ Processing: {source_path}\")\n",
    "            files = os.listdir(source_path)\n",
    "\n",
    "            for f in files:\n",
    "                if f.lower().endswith(('.png', '.jpg', '.jpeg', '.dcm')):\n",
    "                    img_path = os.path.join(source_path, f)\n",
    "\n",
    "                    # Quality check - verify image can be opened and meets size requirements\n",
    "                    try:\n",
    "                        with Image.open(img_path) as img:\n",
    "                            if img.size[0] >= min_image_size[0] and img.size[1] >= min_image_size[1]:\n",
    "                                all_images.append(img_path)\n",
    "                            else:\n",
    "                                skipped += 1\n",
    "                    except Exception as e:\n",
    "                        skipped += 1\n",
    "                        continue\n",
    "\n",
    "    print(f\"  âœ“ Found {len(all_images)} valid images (skipped {skipped} low-quality)\")\n",
    "\n",
    "    if len(all_images) == 0:\n",
    "        print(f\"  âš ï¸ WARNING: No images found for {label}\")\n",
    "        return\n",
    "\n",
    "    # Shuffle\n",
    "    np.random.shuffle(all_images)\n",
    "\n",
    "    # Split\n",
    "    n_train = int(len(all_images) * split_ratio['train'])\n",
    "    n_val = int(len(all_images) * split_ratio['val'])\n",
    "\n",
    "    train_imgs = all_images[:n_train]\n",
    "    val_imgs = all_images[n_train:n_train + n_val]\n",
    "    test_imgs = all_images[n_train + n_val:]\n",
    "\n",
    "    # Copy files with progress bar\n",
    "    for split, imgs in [('train', train_imgs), ('val', val_imgs), ('test', test_imgs)]:\n",
    "        dest_dir = f'{dest_base}/{split}/{label}'\n",
    "        for i, img_path in enumerate(tqdm(imgs, desc=f'{label} {split}')):\n",
    "            try:\n",
    "                # Open, convert to RGB, and save as JPEG for consistency\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                output_path = f'{dest_dir}/{label}_{split}_{i:05d}.jpg'\n",
    "                img.save(output_path, 'JPEG', quality=95)\n",
    "            except Exception as e:\n",
    "                print(f\"  âš ï¸ Error processing {img_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    print(f\"âœ… {label}: Train={len(train_imgs)}, Val={len(val_imgs)}, Test={len(test_imgs)}\")\n",
    "    return len(train_imgs), len(val_imgs), len(test_imgs)\n",
    "\n",
    "# Organize NORMAL images (from pneumonia dataset)\n",
    "print(\"\\nðŸ“‹ Organizing NORMAL images...\")\n",
    "organize_images(\n",
    "    ['/content/chest-xray-pneumonia/chest_xray/train/NORMAL',\n",
    "     '/content/chest-xray-pneumonia/chest_xray/test/NORMAL'],\n",
    "    base_dir, 'NORMAL'\n",
    ")\n",
    "\n",
    "# Organize PNEUMONIA images\n",
    "print(\"\\nðŸ“‹ Organizing PNEUMONIA images...\")\n",
    "organize_images(\n",
    "    ['/content/chest-xray-pneumonia/chest_xray/train/PNEUMONIA',\n",
    "     '/content/chest-xray-pneumonia/chest_xray/test/PNEUMONIA'],\n",
    "    base_dir, 'PNEUMONIA'\n",
    ")\n",
    "\n",
    "# Organize COVID images\n",
    "print(\"\\nðŸ“‹ Organizing COVID images...\")\n",
    "organize_images(\n",
    "    ['/content/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID/images'],\n",
    "    base_dir, 'COVID'\n",
    ")\n",
    "\n",
    "# Organize TB images - IMPROVED WITH MULTIPLE SOURCES\n",
    "print(\"\\nðŸ“‹ Organizing TB images from MULTIPLE high-quality sources...\")\n",
    "\n",
    "tb_sources = []\n",
    "\n",
    "# Source 1: Shenzhen Hospital\n",
    "shenzhen_tb = '/content/tuberculosis-chest-xrays-shenzhen/ChinaSet_AllFiles/ChinaSet_AllFiles'\n",
    "if os.path.exists(shenzhen_tb):\n",
    "    tb_sources.append(shenzhen_tb)\n",
    "    print(\"  âœ“ Shenzhen TB dataset found\")\n",
    "\n",
    "# Alternative Shenzhen path\n",
    "shenzhen_alt = '/content/tuberculosis-chest-xrays-shenzhen/images'\n",
    "if os.path.exists(shenzhen_alt):\n",
    "    tb_sources.append(shenzhen_alt)\n",
    "    print(\"  âœ“ Shenzhen TB dataset (alt path) found\")\n",
    "\n",
    "# Source 2: Montgomery County\n",
    "montgomery_tb = '/content/tuberculosis-chest-xrays-montgomery/MontgomerySet/CXR_png'\n",
    "if os.path.exists(montgomery_tb):\n",
    "    tb_sources.append(montgomery_tb)\n",
    "    print(\"  âœ“ Montgomery TB dataset found\")\n",
    "\n",
    "# Alternative Montgomery path\n",
    "montgomery_alt = '/content/tuberculosis-chest-xrays-montgomery/images'\n",
    "if os.path.exists(montgomery_alt):\n",
    "    tb_sources.append(montgomery_alt)\n",
    "    print(\"  âœ“ Montgomery TB dataset (alt path) found\")\n",
    "\n",
    "# Source 3: TBX11K (if available) - This is the best quality dataset\n",
    "tbx11k_paths = [\n",
    "    '/content/tbx-11/TBX11K',\n",
    "    '/content/tbx-11/images',\n",
    "    '/content/tbx-11/TB',\n",
    "]\n",
    "\n",
    "for path in tbx11k_paths:\n",
    "    if os.path.exists(path):\n",
    "        # TBX11K may have subdirectories\n",
    "        for subdir in os.listdir(path):\n",
    "            subpath = os.path.join(path, subdir)\n",
    "            if os.path.isdir(subpath):\n",
    "                tb_sources.append(subpath)\n",
    "        tb_sources.append(path)\n",
    "        print(f\"  âœ“ TBX11K dataset found at {path}\")\n",
    "        break\n",
    "\n",
    "if len(tb_sources) == 0:\n",
    "    print(\"  âš ï¸ WARNING: No TB datasets found! Check download paths.\")\n",
    "else:\n",
    "    print(f\"  ðŸ“Š Using {len(tb_sources)} TB data source(s)\")\n",
    "    organize_images(tb_sources, base_dir, 'TB', min_image_size=(224, 224))\n",
    "\n",
    "print(\"\\nâœ… All data organized with quality checks!\")\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 5: DATA EXPLORATION & VALIDATION\n",
    "# ==========================================\n",
    "\n",
    "# Count images in each category\n",
    "def count_images(base_path):\n",
    "    stats = {}\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        stats[split] = {}\n",
    "        for category in ['NORMAL', 'PNEUMONIA', 'COVID', 'TB']:\n",
    "            path = f'{base_path}/{split}/{category}'\n",
    "            if os.path.exists(path):\n",
    "                stats[split][category] = len([f for f in os.listdir(path) if f.endswith('.jpg')])\n",
    "            else:\n",
    "                stats[split][category] = 0\n",
    "    return stats\n",
    "\n",
    "stats = count_images(base_dir)\n",
    "df_stats = pd.DataFrame(stats).T\n",
    "\n",
    "print(\"\\nðŸ“Š Dataset Statistics:\")\n",
    "print(df_stats)\n",
    "print(f\"\\nðŸ“ˆ Total Images: {df_stats.values.sum()}\")\n",
    "print(f\"ðŸ“ˆ TB Images: {df_stats['TB'].sum()}\")\n",
    "\n",
    "# Check for class imbalance\n",
    "train_stats = stats['train']\n",
    "max_count = max(train_stats.values())\n",
    "min_count = min([v for v in train_stats.values() if v > 0])\n",
    "imbalance_ratio = max_count / min_count if min_count > 0 else 0\n",
    "\n",
    "print(f\"\\nâš–ï¸ Class Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "if imbalance_ratio > 3:\n",
    "    print(\"  âš ï¸ Significant class imbalance detected - using weighted loss\")\n",
    "\n",
    "# Visualize distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c', '#f39c12']\n",
    "\n",
    "for idx, split in enumerate(['train', 'val', 'test']):\n",
    "    data = stats[split]\n",
    "    bars = axes[idx].bar(data.keys(), data.values(), color=colors)\n",
    "    axes[idx].set_title(f'{split.upper()} Set Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Number of Images', fontsize=12)\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[idx].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                      f'{int(height)}',\n",
    "                      ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize sample images from each class\n",
    "def show_class_samples(base_path, split='train', n_per_class=3):\n",
    "    classes = ['NORMAL', 'PNEUMONIA', 'COVID', 'TB']\n",
    "    fig, axes = plt.subplots(4, n_per_class, figsize=(n_per_class*4, 16))\n",
    "\n",
    "    for i, cls in enumerate(classes):\n",
    "        class_dir = f'{base_path}/{split}/{cls}'\n",
    "        if os.path.exists(class_dir):\n",
    "            images = [f for f in os.listdir(class_dir) if f.endswith('.jpg')][:n_per_class]\n",
    "\n",
    "            for j, img_name in enumerate(images):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                img = Image.open(img_path)\n",
    "                axes[i, j].imshow(img, cmap='gray')\n",
    "                axes[i, j].set_title(f'{cls}', fontsize=12, fontweight='bold')\n",
    "                axes[i, j].axis('off')\n",
    "\n",
    "    plt.suptitle(f'Sample X-Ray Images from {split.upper()} Set', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nðŸ“¸ Displaying sample images from each class:\")\n",
    "show_class_samples(base_dir, 'train', n_per_class=4)\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 6: DATASET CLASS\n",
    "# ==========================================\n",
    "\n",
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.classes = ['NORMAL', 'PNEUMONIA', 'COVID', 'TB']\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "        # Load all image paths and labels\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(root_dir, split, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        self.images.append(os.path.join(class_dir, img_name))\n",
    "                        self.labels.append(self.class_to_idx[class_name])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 7: ENHANCED DATA AUGMENTATION\n",
    "# ==========================================\n",
    "\n",
    "# Training transforms with stronger augmentation for medical images\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation/Test transforms (no augmentation)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ChestXrayDataset(base_dir, split='train', transform=train_transform)\n",
    "val_dataset = ChestXrayDataset(base_dir, split='val', transform=val_transform)\n",
    "test_dataset = ChestXrayDataset(base_dir, split='test', transform=val_transform)\n",
    "\n",
    "print(f\"âœ… Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\")\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 8: DATA LOADERS\n",
    "# ==========================================\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(\"âœ… Data loaders created!\")\n",
    "\n",
    "# Visualize sample batch\n",
    "def show_batch(dataloader, n=8):\n",
    "    batch = next(iter(dataloader))\n",
    "    images, labels = batch\n",
    "\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    classes = ['NORMAL', 'PNEUMONIA', 'COVID', 'TB']\n",
    "\n",
    "    for i in range(min(n, len(images))):\n",
    "        img = images[i].cpu().numpy().transpose(1, 2, 0)\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Label: {classes[labels[i]]}\", fontsize=12, fontweight='bold')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nðŸ“¸ Sample images from training set:\")\n",
    "show_batch(train_loader)\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 9: MODEL ARCHITECTURE\n",
    "# ==========================================\n",
    "\n",
    "class XRayClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4, pretrained=True):\n",
    "        super(XRayClassifier, self).__init__()\n",
    "\n",
    "        # Use EfficientNet-B0 (better than ResNet50 for medical images)\n",
    "        self.backbone = models.efficientnet_b0(pretrained=pretrained)\n",
    "\n",
    "        # Replace classifier\n",
    "        in_features = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = XRayClassifier(num_classes=4, pretrained=True).to(device)\n",
    "\n",
    "print(f\"âœ… Model created on {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 10: IMPROVED LOSS & OPTIMIZER\n",
    "# ==========================================\n",
    "\n",
    "# Calculate class weights for imbalanced dataset - IMPROVED\n",
    "class_counts = [stats['train'][cls] for cls in ['NORMAL', 'PNEUMONIA', 'COVID', 'TB']]\n",
    "print(f\"\\nðŸ“Š Class counts: {dict(zip(['NORMAL', 'PNEUMONIA', 'COVID', 'TB'], class_counts))}\")\n",
    "\n",
    "# Handle zero counts and calculate balanced weights\n",
    "class_weights = []\n",
    "for count in class_counts:\n",
    "    if count > 0:\n",
    "        class_weights.append(1.0 / count)\n",
    "    else:\n",
    "        class_weights.append(0.0)\n",
    "        print(f\"  âš ï¸ Warning: Zero samples found for a class\")\n",
    "\n",
    "class_weights = torch.FloatTensor(class_weights)\n",
    "if class_weights.sum() > 0:\n",
    "    class_weights = class_weights / class_weights.sum() * len(class_weights)  # Normalize\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "print(f\"Class weights: {class_weights.cpu().numpy()}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
    "\n",
    "print(\"âœ… Loss function and optimizer configured!\")\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 11: TRAINING FUNCTIONS\n",
    "# ==========================================\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(dataloader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        pbar.set_postfix({'loss': running_loss/len(dataloader), 'acc': 100.*correct/total})\n",
    "\n",
    "    return running_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc='Validation')\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            pbar.set_postfix({'loss': running_loss/len(dataloader), 'acc': 100.*correct/total})\n",
    "\n",
    "    return running_loss / len(dataloader), 100. * correct / total, all_preds, all_labels\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 12: TRAINING LOOP\n",
    "# ==========================================\n",
    "\n",
    "num_epochs = 20\n",
    "best_val_acc = 0.0\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "print(\"\\nðŸš€ Starting Training...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "\n",
    "    # Validate\n",
    "    val_loss, val_acc, val_preds, val_labels = validate_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "    # Update scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "        }, 'best_xray_model.pth')\n",
    "        print(f\"âœ… New best model saved! Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    print()\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Training Complete! Best Val Accuracy: {best_val_acc:.2f}%\")\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 13: PLOT TRAINING HISTORY\n",
    "# ==========================================\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(history['train_loss'], label='Train Loss', marker='o', linewidth=2)\n",
    "ax1.plot(history['val_loss'], label='Val Loss', marker='s', linewidth=2)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(history['train_acc'], label='Train Acc', marker='o', linewidth=2)\n",
    "ax2.plot(history['val_acc'], label='Val Acc', marker='s', linewidth=2)\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax2.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 14: TEST EVALUATION\n",
    "# ==========================================\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load('best_xray_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(\"âœ… Best model loaded!\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_preds, test_labels = validate_epoch(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"\\nðŸ“Š Test Set Performance:\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "# Classification Report\n",
    "classes = ['NORMAL', 'PNEUMONIA', 'COVID', 'TB']\n",
    "print(\"\\nðŸ“‹ Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=classes, zero_division=0))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes, cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - Test Set', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Per-class accuracy\n",
    "print(\"\\nðŸ“ˆ Per-Class Accuracy:\")\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "for i, cls in enumerate(classes):\n",
    "    print(f\"  {cls:12s}: {class_accuracy[i]*100:.2f}%\")\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 15: EXPORT MODEL\n",
    "# ==========================================\n",
    "\n",
    "# Export for deployment\n",
    "torch.save(model.state_dict(), 'xray_model_weights.pth')\n",
    "torch.save(model, 'xray_model_complete.pth')\n",
    "\n",
    "# Save model info\n",
    "model_info = {\n",
    "    'accuracy': test_acc,\n",
    "    'classes': classes,\n",
    "    'input_size': (224, 224),\n",
    "    'num_parameters': sum(p.numel() for p in model.parameters()),\n",
    "    'tb_sources': len(tb_sources),\n",
    "    'dataset_stats': stats\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "print(\"\\nâœ… Model exported successfully!\")\n",
    "print(\"Files saved:\")\n",
    "print(\"  - best_xray_model.pth (checkpoint)\")\n",
    "print(\"  - xray_model_weights.pth (weights only)\")\n",
    "print(\"  - xray_model_complete.pth (complete model)\")\n",
    "print(\"  - model_info.json (metadata)\")\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 16: GRADCAM IMPLEMENTATION\n",
    "# ==========================================\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "class GradCAMVisualizer:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        # Target the last convolutional layer\n",
    "        target_layer = model.backbone.features[-1]\n",
    "        self.cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "\n",
    "    def generate_heatmap(self, image_tensor, predicted_class):\n",
    "        \"\"\"Generate GradCAM heatmap for an image\"\"\"\n",
    "        grayscale_cam = self.cam(input_tensor=image_tensor.unsqueeze(0),\n",
    "                                  targets=[predicted_class])\n",
    "        return grayscale_cam[0]\n",
    "\n",
    "# Test GradCAM\n",
    "gradcam = GradCAMVisualizer(model, device)\n",
    "\n",
    "# Get sample images\n",
    "sample_images, sample_labels = next(iter(test_loader))\n",
    "sample_images = sample_images[:4].to(device)\n",
    "sample_labels = sample_labels[:4]\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(sample_images)\n",
    "    _, predictions = outputs.max(1)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(4):\n",
    "    # Original image\n",
    "    img = sample_images[i].cpu().numpy().transpose(1, 2, 0)\n",
    "    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    img = np.clip(img, 0, 1)\n",
    "\n",
    "    # Generate heatmap\n",
    "    heatmap = gradcam.generate_heatmap(sample_images[i], predictions[i].item())\n",
    "\n",
    "    # Overlay\n",
    "    cam_image = show_cam_on_image(img, heatmap, use_rgb=True)\n",
    "\n",
    "    # Plot\n",
    "    axes[0, i].imshow(img)\n",
    "    axes[0, i].set_title(f\"True: {classes[sample_labels[i]]}\", fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "    axes[1, i].imshow(cam_image)\n",
    "    axes[1, i].set_title(f\"Pred: {classes[predictions[i]]}\", fontsize=10)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('GradCAM Visualizations - Red areas show where AI is looking', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… GradCAM visualization complete!\")\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 17: INFERENCE FUNCTION\n",
    "# ==========================================\n",
    "\n",
    "def predict_xray(model, image_path, device, transform):\n",
    "    \"\"\"\n",
    "    Predict disease from X-ray image\n",
    "\n",
    "    Returns:\n",
    "        prediction: class name\n",
    "        confidence: probability score\n",
    "        heatmap: GradCAM visualization\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        probabilities = F.softmax(output, dim=1)\n",
    "        confidence, predicted = probabilities.max(1)\n",
    "\n",
    "    # Get class name\n",
    "    classes = ['NORMAL', 'PNEUMONIA', 'COVID', 'TB']\n",
    "    prediction = classes[predicted.item()]\n",
    "    confidence_score = confidence.item() * 100\n",
    "\n",
    "    # Generate heatmap\n",
    "    gradcam_viz = GradCAMVisualizer(model, device)\n",
    "    heatmap = gradcam_viz.generate_heatmap(image_tensor[0], predicted.item())\n",
    "\n",
    "    return prediction, confidence_score, heatmap\n",
    "\n",
    "# Test inference\n",
    "test_image_path = test_dataset.images[0]\n",
    "prediction, confidence, heatmap = predict_xray(model, test_image_path, device, val_transform)\n",
    "\n",
    "print(f\"\\nðŸ” Inference Test:\")\n",
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Confidence: {confidence:.2f}%\")\n",
    "\n",
    "# ==========================================\n",
    "# SECTION 18: SAVE FOR DEPLOYMENT\n",
    "# ==========================================\n",
    "\n",
    "# Create deployment package\n",
    "import zipfile\n",
    "\n",
    "deployment_files = [\n",
    "    'best_xray_model.pth',\n",
    "    'xray_model_weights.pth',\n",
    "    'xray_model_complete.pth',\n",
    "    'model_info.json'\n",
    "]\n",
    "\n",
    "with zipfile.ZipFile('xray_model_deployment.zip', 'w') as zipf:\n",
    "    for file in deployment_files:\n",
    "        if os.path.exists(file):\n",
    "            zipf.write(file)\n",
    "\n",
    "print(\" Deployment package created: xray_model_deployment.zip\")\n",
    "print(\" ALL DONE! Your model is ready for deployment!\")\n",
    "print(f\"Final Metrics:\")\n",
    "print(f\"   Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"   Model Size: ~{os.path.getsize('xray_model_complete.pth') / (1024*1024):.1f} MB\")\n",
    "print(f\"   Classes: {', '.join(classes)}\")\n",
    "print(f\"   TB Data Sources: {len(tb_sources) if len(tb_sources) > 0 else 'Warning: No TB data!'}\")\n",
    "print(f\"Download the model files to deploy in your backend!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
